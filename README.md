# 2004
Python自然语言处理-BERT实战 | 完结
### 微:NoBug1024 


课程介绍：

Python自然语言处理-BERT模型实战课程旨在帮助同学们快速掌握当下NLP领域最核心的算法模型BERT的原理构造与应用实例。通俗讲解BERT模型中所涉及的核心知识点（Transformer,self-attention等），基于google开源BERT项目从零开始讲解如何搭建自然语言处理通用框架，通过debug源码详细解读其中每一核心代码模块的功能与作用。最后基于BERT框架进行中文情感分析与命名实体识别等主流项目实战，提供全部课程资料，包括PPT,数据,代码。

〖课程目录〗:

- ├──资料  
- |   └──资料.7z  1.84G
- ├──1-1 BERT课程简介.mp4  12.44M
- ├──1-10 BERT模型训练方法.mp4  13.45M
- ├──1-11 训练实例.mp4  14.89M
- ├──1-2 BERT任务目标概述.mp4  7.57M
- ├──1-3 传统解决方案遇到的问题.mp4  14.94M
- ├──1-4 注意力机制的作用.mp4  9.50M
- ├──1-5 self-attention计算方法.mp4  15.62M
- ├──1-6 特征分配与softmax机制.mp4  13.42M
- ├──1-7 Multi-head的作用.mp4  12.73M
- ├──1-8 位置编码与多层堆叠.mp4  10.87M
- ├──1-9 transformer整体架构梳理.mp4  15.27M
- ├──2-1 BERT开源项目简介.mp4  21.45M
- ├──2-10 构建QKV矩阵.mp4  27.66M
- ├──2-11 完成Transformer模块构建.mp4  23.00M
- ├──2-12 训练BERT模型.mp4  30.50M
- ├──2-2 项目参数配置.mp4  52.51M
- ├──2-3 数据读取模块.mp4  27.79M
- ├──2-4 数据预处理模块.mp4  24.44M
- ├──2-5 tfrecord制作.mp4  28.49M
- ├──2-6 Embedding层的作用.mp4  17.76M
- ├──2-7 加入额外编码特征.mp4  23.58M
- ├──2-8 加入位置编码特征.mp4  12.82M
- ├──2-9 mask机制.mp4  20.85M
- ├──3-1 中文分类数据与任务概述.mp4  35.80M
- ├──3-2 读取处理自己的数据集.mp4  29.75M
- ├──3-3 训练BERT中文分类模型.mp4  38.14M
- ├──4-1 命名实体识别数据分析与任务目标.mp4  17.36M
- ├──4-2 NER标注数据处理与读取.mp4  36.89M
- ├──4-3 构建BERT与CRF模型.mp4  36.54M
- ├──5-1 词向量模型通俗解释.mp4  11.45M
- ├──5-2 模型整体框架.mp4  15.11M
- ├──5-3 训练数据构建.mp4  8.47M
- ├──5-4 CBOW与Skip-gram模型.mp4  13.01M
- ├──5-5 负采样方案.mp4  14.57M
- ├──6-1 数据与任务流程.mp4  25.95M
- ├──6-2 数据清洗.mp4  13.96M
- ├──6-3 batch数据制作.mp4  25.61M
- ├──6-4 网络训练.mp4  25.81M
- ├──6-5 可视化展示.mp4  22.87M
- ├──7-1 RNN网络模型解读.mp4  16.13M
- ├──7-2 NLP应用领域与任务简介.mp4  18.31M
- ├──7-3 项目流程解读.mp4  23.65M
- ├──7-4 加载词向量特征.mp4  17.72M
- ├──7-5 正负样本数据读取.mp4  19.68M
- ├──7-6 构建LSTM网络模型.mp4  26.44M
- ├──7-7 训练与测试效果.mp4  47.01M
- ├──8-1 数据与任务介绍.mp4  11.46M
- ├──8-2 整体模型架构.mp4  8.09M
- ├──8-3 数据-标签-语料库处理.mp4  19.66M
- ├──8-4 输入样本填充补齐.mp4  17.69M
- ├──8-5 训练网络模型.mp4  21.02M
- ├──8-6 医疗数据集（糖尿病）实体识别.mp4  46.71M
- └──数据代码.txt  0.11kb
